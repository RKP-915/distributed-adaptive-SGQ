{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iVaqz7rvWmy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Callable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptiveSGQ:\n",
        "    def __init__(self,\n",
        "                 functions: List[Callable],\n",
        "                 learning_rate: float = 0.01,\n",
        "                 initial_p: float = 0.2,\n",
        "                 min_p: float = 0.1,\n",
        "                 max_p: float = 0.5,\n",
        "                 switch_threshold: float = 0.001,\n",
        "                 L: float = 1.0):\n",
        "\n",
        "        self.functions = functions\n",
        "        self.n_functions = len(functions)\n",
        "        self.lr = learning_rate\n",
        "        self.current_p = initial_p\n",
        "        self.min_p = min_p\n",
        "        self.max_p = max_p\n",
        "        self.switch_threshold = switch_threshold\n",
        "        self.L = L\n",
        "\n",
        "        self.x = torch.randn(5, requires_grad=True)\n",
        "        self.iteration = 0\n",
        "        self.best_loss = float('inf')\n",
        "\n",
        "        self.loss_history = []\n",
        "        self.p_history = []\n",
        "        self.mode_history = []\n",
        "        self.algorithm_mode = 'SGQ'\n",
        "\n",
        "        print(f'Initialized adaptive SGQ with p={initial_p} & mode={self.algorithm_mode}')\n",
        "\n",
        "    def compute_ei(self, gradient: Tensor, full_gradient: Tensor) -> float:\n",
        "        alpha = self.lr\n",
        "        ei = (alpha * torch.dot(full_gradient, gradient) -\n",
        "              (alpha ** 2 * self.L / 2) * torch.norm(gradient)**2)\n",
        "        return ei.item()\n",
        "\n",
        "    def Adaptive_p_update(self, current_loss: float, improvement: float):\n",
        "      if improvement > 0.05:\n",
        "        self.current_p = max(self.min_p, self.current_p * 0.9)\n",
        "\n",
        "      elif improvement < 0.005:\n",
        "        self.current_p = min(self.max_p, self.current_p * 1.1)\n",
        "\n",
        "      if (current_loss < self.switch_threshold and self.algorithm_mode and\n",
        "        self.algorithm_mode == 'SGQ' and self.iteration > 100):\n",
        "\n",
        "        self.algorithm_mode = 'SGD'\n",
        "        print(f'switching to SGD at iteration {self.iteration} (loss: {current_loss:.6f})')\n",
        "\n",
        "    def strategic_selection(self) -> int:\n",
        "      gradients= []\n",
        "      for i in range(self.n_functions):\n",
        "        self.x.grad = None\n",
        "        loss = self.functions[i](self.x)\n",
        "        loss.backward()\n",
        "        if self.x.grad is not None:\n",
        "          gradients.append(self.x.grad.clone())\n",
        "        else:\n",
        "          gradients.append(torch.zeros_like(self.x))\n",
        "\n",
        "      full_gradient = torch.mean(torch.stack(gradients), dim= 0)\n",
        "\n",
        "      if np.random.random() < self.current_p:\n",
        "        selected_index = np.random.randint(self.n_functions)\n",
        "        return selected_index\n",
        "\n",
        "      eis = []\n",
        "      for grad in gradients:\n",
        "        ei = self.compute_ei(grad, full_gradient)\n",
        "        eis.append(ei)\n",
        "\n",
        "      selected_index = np.argmax(eis)\n",
        "\n",
        "      return selected_index\n",
        "\n",
        "    def compute_current_loss(self) -> float:\n",
        "      total_loss = 0\n",
        "      for function in self.functions:\n",
        "        total_loss += function(self.x).item()\n",
        "      return total_loss / self.n_functions\n",
        "\n",
        "    def optimize_step(self):\n",
        "      if self.algorithm_mode == 'SGQ':\n",
        "        #sgq phase\n",
        "        selected_index = self.strategic_selection()\n",
        "      else:\n",
        "        #sgd phase\n",
        "        selected_index = np.random.randint(self.n_functions)\n",
        "\n",
        "      self.x.grad = None\n",
        "      loss = self.functions[selected_index](self.x)\n",
        "      loss.backward()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        if self.x.grad is not None:\n",
        "          self.x -= self.lr * self.x.grad\n",
        "\n",
        "      current_loss = self.compute_current_loss()\n",
        "      improvement = self.best_loss - current_loss if self.best_loss != float('inf') else 0\n",
        "\n",
        "      if current_loss < self.best_loss:\n",
        "        self.best_loss = current_loss\n",
        "\n",
        "      #adaptive p update(sgq)\n",
        "      if self.algorithm_mode == 'SGQ':\n",
        "        self.Adaptive_p_update(current_loss, improvement)\n",
        "\n",
        "      #history\n",
        "      self.loss_history.append(current_loss)\n",
        "      self.p_history.append(self.current_p)\n",
        "      self.mode_history.append(self.algorithm_mode)\n",
        "      self.iteration += 1\n",
        "\n",
        "      return current_loss\n",
        "\n",
        "    def optimize(self, iterations: int = 1000, verbose: bool = True):\n",
        "      print(f'starting optimization with {self.algorithm_mode}')\n",
        "      print(f'initial p: {self.current_p:.3f}')\n",
        "      print(f'switch threshold: {self.switch_threshold}')\n",
        "\n",
        "      for i in range(iterations):\n",
        "        loss = self.optimize_step()\n",
        "\n",
        "        if verbose and i % 100 == 0:\n",
        "          mode_indirector = 'ðŸ”µ' if self.algorithm_mode == 'SGQ' else 'ðŸ”´'\n",
        "          print(f'{mode_indirector} iteration {i}: loss ={loss:.6f}, p = {self.current_p:.3f}')\n",
        "\n",
        "        # early stopping\n",
        "        if loss < 1e-6:\n",
        "          print(f'coverged at iteration {i}')\n",
        "          break\n",
        "\n",
        "        final_mode = 'SGD' if self.algorithm_mode == 'SGD' else 'SGQ'\n",
        "        print(f'optimization completed in {self.iteration} iterations')\n",
        "        print(f'final mode: {final_mode}')\n",
        "        print(f'final loss: {self.loss_history[-1]:.6f}')\n",
        "        print(f'final p: {self.p_history[-1]:.3f}')"
      ],
      "metadata": {
        "id": "dS3fQzc9vxsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a426c04"
      },
      "source": [
        "    def plot_results(self, save_path: str = 'adaptive_sgq_results.png'):\n",
        "      fig, ((ax1, ax2), (ax3, ax4))= plt.subplot(2, 2, figsize=(12,8))\n",
        "\n",
        "      #loss history\n",
        "      ax1.semilogy(self.loss_history)\n",
        "      ax1.set_xlabel('iteration')\n",
        "      ax1.set_ylabel('loss')\n",
        "      ax1.set_title('optimization progress')\n",
        "      ax1.grid(True, alpha=0.3)\n",
        "\n",
        "      #algorithm switch\n",
        "      if 'SGD' in self.mode_history:\n",
        "        switch_iter = self.mode_history.index('SGD')\n",
        "        ax1.axvline(x=switch_iter, color='red', linestyle='--', alpha=0.7, label='sgq->sgd')\n",
        "        ax1.legend()\n",
        "\n",
        "      #p adaption\n",
        "      ax2.semilogy(self.p_history)\n",
        "      ax2.set_xlabel('iteration')\n",
        "      ax2.set_ylabel('exploration probability (p)')\n",
        "      ax2.set_title('adaptive p parameter')\n",
        "      ax2.grid(True, alpha=0.3)\n",
        "\n",
        "      #mode history\n",
        "      mode_numeric = [1 if mode == 'SGQ' else 0 for mode in self.mode_history]\n",
        "      ax3.plot(mode_numeric)\n",
        "      ax3.set_xlabel('iteration')\n",
        "      ax3.set_ylabel('algorithm mode')\n",
        "      ax3.set_title('sgq (1) vs sgd(0) mode')\n",
        "      ax3.set_yticks([0, 1])\n",
        "      ax3.set_yticklabels(['SGD', 'SGQ'])\n",
        "      ax3.grid(True, alpha=0.3)\n",
        "\n",
        "      #improvement rate\n",
        "      improvements = [0] + [-self.loss_history[i] + self.loss_history[i-1] for i in range(len(self.loss_history))]\n",
        "      ax4.plot(improvements)\n",
        "      ax4.set_xlabel('iteration')\n",
        "      ax4.set_ylabel('improvement rate')\n",
        "      ax4.set_title('loss improvement per iteration')\n",
        "      ax4.grid(True, alpha=0.3)\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "      plt.show()\n",
        "\n",
        "      return fig\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example\n",
        "def create_heterogeneous_functions(n_functions: int = 8):\n",
        "  functions=[]\n",
        "\n",
        "  centers = [\n",
        "      torch.tensor([1.0, 1.0, 0.5, -0.5, 0.0]),\n",
        "      torch.tensor([-1.0, 2.0, -0.5, 1.0, 0.5]),\n",
        "      torch.tensor([0.5, -1.0, 1.0, -1.0, 1.0]),\n",
        "      torch.tensor([-2.0, -0.5, 0.0, 0.5, -1.0]),\n",
        "      torch.tensor([1.5, 0.0, -1.0, 1.5, 0.5]),\n",
        "      torch.tensor([-1.0, -2.0, 0.5, -0.5, 1.0]),\n",
        "      torch.tensor([0.0, 1.5, -1.5, 1.0, -0.5]),\n",
        "      torch.tensor([2.0, -1.0, 1.0, -1.5, 0.0]),\n",
        "  ]\n",
        "\n",
        "  for i, center in enumerate(centers[:n_functions]):\n",
        "    scale = 0.5 + 0.3 * (i % 3)\n",
        "\n",
        "    def make_func(c=center.clone(), s=scale):\n",
        "      def func(x):\n",
        "        return s * torch.norm(x - c)**2\n",
        "      return func\n",
        "\n",
        "    functions.append(make_func())\n",
        "\n",
        "  return functions\n",
        "\n",
        "  #demo execution\n",
        "  if __name__ == '__main__':\n",
        "    test_functions = create_heterogeneous_functions()\n",
        "\n",
        "    optimizer = AdaptiveSGQ(\n",
        "        functions = test_functions,\n",
        "        learning_rate = 0.1,\n",
        "        initial_p = 0.2,\n",
        "        switch_threshold = 0.01\n",
        "        )\n",
        "\n",
        "    optimizer.optimize(iterations=500)\n",
        "\n",
        "    optimizer.plot_results()"
      ],
      "metadata": {
        "id": "AGSBXvDtMmV2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}