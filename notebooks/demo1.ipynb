{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Callable"
      ],
      "metadata": {
        "id": "z44yF7OkODyO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaptiveSGQ:\n",
        "\n",
        "    def __init__(self, functions: List[Callable[[Tensor], Tensor]], learning_rate: float = 0.1,\n",
        "                 initial_p: float = 0.3, switch_threshold: float = 0.1, dim: int = 2):\n",
        "        self.functions = functions\n",
        "        self.n_functions = len(functions)\n",
        "        self.lr = learning_rate\n",
        "        self.current_p = initial_p\n",
        "        self.min_p = 0.05\n",
        "        self.max_p = 0.8\n",
        "        self.switch_threshold = switch_threshold\n",
        "        self.algorithm_mode = 'SGQ'\n",
        "        self.iteration = 0\n",
        "        self.loss_history = []\n",
        "        self.p_history = []\n",
        "        self.mode_history = []\n",
        "        self.best_loss = float('inf')\n",
        "        self.stagnation_count = 0\n",
        "        self.x = torch.nn.Parameter(torch.randn(dim) * 0.5, requires_grad=True)\n",
        "\n",
        "\n",
        "    def Adaptive_p_update(self, current_loss: float, improvement: float):\n",
        "      # Tracking improvement history\n",
        "        if not hasattr(self, 'improvement_history'):\n",
        "          self.improvement_history = []\n",
        "\n",
        "        self.improvement_history.append(improvement)\n",
        "        if len(self.improvement_history) > 10:\n",
        "          self.improvement_history.pop(0)\n",
        "\n",
        "\n",
        "        avg_improvement = np.mean(self.improvement_history) if self.improvement_history else 0\n",
        "\n",
        "    # Adaptive p-update\n",
        "        if improvement > 0.02:\n",
        "          self.current_p = max(self.min_p, self.current_p * 0.9)\n",
        "        elif improvement < 0.005:\n",
        "          self.current_p = min(self.max_p, self.current_p * 1.1)\n",
        "\n",
        "        recent_avg = 0\n",
        "        older_avg = 0\n",
        "\n",
        "\n",
        "        if len(self.improvement_history) >= 10:\n",
        "          recent_avg = np.mean(self.improvement_history[-5:])\n",
        "          older_avg = np.mean(self.improvement_history[:5])\n",
        "\n",
        "          if recent_avg < older_avg * 0.3:\n",
        "              if self.algorithm_mode == 'SGQ':\n",
        "                  self.algorithm_mode = 'SGD'\n",
        "                  print(f'ðŸ”„ Switching to SGD at iteration {self.iteration} (improvement stalled)')\n",
        "              else:\n",
        "                  self.algorithm_mode = 'SGQ'\n",
        "                  print(f'ðŸ”„ Switching back to SGQ at iteration {self.iteration}')\n",
        "\n",
        "              # Reset improvement history after switch\n",
        "              self.improvement_history = []\n",
        "\n",
        "\n",
        "        if (current_loss < self.switch_threshold and\n",
        "          self.algorithm_mode == 'SGQ' and\n",
        "          self.iteration > 100):\n",
        "          self.algorithm_mode = 'SGD'\n",
        "          print(f'ðŸ“‰ Switching to SGD at iteration {self.iteration} (loss: {current_loss:.6f})')\n",
        "\n",
        "\n",
        "    def strategic_selection(self) -> int:\n",
        "        gradients = []\n",
        "        for i in range(self.n_functions):\n",
        "            self.x.grad = None\n",
        "            loss = self.functions[i](self.x)\n",
        "            loss.backward(retain_graph=True)\n",
        "            if self.x.grad is not None:\n",
        "                gradients.append(self.x.grad.clone())\n",
        "            else:\n",
        "                gradients.append(torch.zeros_like(self.x))\n",
        "\n",
        "        full_gradient = torch.mean(torch.stack(gradients), dim=0)\n",
        "\n",
        "        if np.random.random() < self.current_p:\n",
        "            return np.random.randint(self.n_functions)\n",
        "\n",
        "        eis = []\n",
        "        for grad in gradients:\n",
        "            ei = torch.norm(grad - full_gradient).item()\n",
        "            eis.append(ei)\n",
        "\n",
        "        return np.argmax(eis)\n",
        "\n",
        "    def compute_current_loss(self) -> float:\n",
        "        total_loss = 0\n",
        "        for function in self.functions:\n",
        "            total_loss += function(self.x).item()\n",
        "        return total_loss / self.n_functions\n",
        "\n",
        "    def optimize_step(self):\n",
        "        if self.algorithm_mode == 'SGQ':\n",
        "            selected_index = self.strategic_selection()\n",
        "        else:\n",
        "            selected_index = np.random.randint(self.n_functions)\n",
        "\n",
        "        previous_loss = self.compute_current_loss() if self.loss_history else None\n",
        "\n",
        "        self.x.grad = None\n",
        "        loss = self.functions[selected_index](self.x)\n",
        "        loss.backward()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if self.x.grad is not None:\n",
        "                self.x -= self.lr * self.x.grad\n",
        "\n",
        "        current_loss = self.compute_current_loss()\n",
        "\n",
        "        if previous_loss is not None:\n",
        "          improvement = previous_loss - current_loss\n",
        "        else:\n",
        "          improvement = 0\n",
        "\n",
        "        if self.best_loss != float('inf'):\n",
        "            improvement = self.best_loss - current_loss\n",
        "            if improvement < 1e-5:\n",
        "                self.stagnation_count += 1\n",
        "            else:\n",
        "                self.stagnation_count = 0\n",
        "        else:\n",
        "            improvement = 0\n",
        "\n",
        "        if current_loss < self.best_loss:\n",
        "            self.best_loss = current_loss\n",
        "\n",
        "        if self.algorithm_mode == 'SGQ':\n",
        "            self.Adaptive_p_update(current_loss, improvement)\n",
        "\n",
        "        self.loss_history.append(current_loss)\n",
        "        self.p_history.append(self.current_p)\n",
        "        self.mode_history.append(self.algorithm_mode)\n",
        "        self.iteration += 1\n",
        "\n",
        "        return current_loss\n",
        "\n",
        "    def optimize(self, iterations: int = 1000, patience: int = 100, verbose: bool = True):\n",
        "      print(f'Starting optimization with {self.algorithm_mode}')\n",
        "      print(f'Initial p: {self.current_p:.3f}')\n",
        "      print(f'Switch threshold: {self.switch_threshold}')\n",
        "\n",
        "      no_improvement_count = 0\n",
        "      best_loss = float('inf')\n",
        "\n",
        "      for i in range(iterations):\n",
        "          loss = self.optimize_step()\n",
        "\n",
        "          if loss < best_loss:\n",
        "              best_loss = loss\n",
        "              no_improvement_count = 0\n",
        "          else:\n",
        "              no_improvement_count += 1\n",
        "\n",
        "          if verbose and i % 100 == 0:\n",
        "              mode_indicator = 'ðŸ”µ' if self.algorithm_mode == 'SGQ' else 'ðŸ”´'\n",
        "              print(f'{mode_indicator} Iteration {i}: Loss = {loss:.6f}, p = {self.current_p:.3f}')\n",
        "\n",
        "          # Early stopping\n",
        "          if loss < 1e-6:\n",
        "              print(f'Converged at iteration {i}')\n",
        "              break\n",
        "\n",
        "          if no_improvement_count >= patience:\n",
        "              print(f'Early stopping at iteration {i} (no improvement for {patience} iterations)')\n",
        "              break\n",
        "\n",
        "\n",
        "      final_mode = 'SGD' if self.algorithm_mode == 'SGD' else 'SGQ'\n",
        "      print(f'Optimization completed in {self.iteration} iterations')\n",
        "      print(f'Final mode: {final_mode}')\n",
        "      print(f'Final loss: {self.loss_history[-1]:.6f}')\n",
        "      print(f'Final p: {self.p_history[-1]:.3f}')"
      ],
      "metadata": {
        "id": "jwOms5I3OHDm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_heterogeneous_functions(n_functions: int = 4):\n",
        "    functions = []\n",
        "\n",
        "    centers = [\n",
        "        torch.tensor([2.0, 2.0]),\n",
        "        torch.tensor([-2.0, -2.0]),\n",
        "        torch.tensor([1.5, -1.5]),\n",
        "        torch.tensor([-1.5, 1.5]),\n",
        "    ]\n",
        "\n",
        "\n",
        "    scales = [1.0, 0.8, 1.2, 0.9]\n",
        "\n",
        "    for i, center in enumerate(centers[:n_functions]):\n",
        "        scale = scales[i]\n",
        "\n",
        "        def make_func(c=center.clone(), s=scale):\n",
        "            def func(x):\n",
        "                return s * torch.norm(x - c)**2\n",
        "            return func\n",
        "\n",
        "        functions.append(make_func())\n",
        "\n",
        "    return functions"
      ],
      "metadata": {
        "id": "7Io_t_cmPjzQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_functions = create_heterogeneous_functions()\n",
        "\n",
        "optimizer = AdaptiveSGQ(\n",
        "    functions=test_functions,\n",
        "    learning_rate=0.005,\n",
        "    initial_p=0.4,\n",
        "    switch_threshold=0.5\n",
        ")\n",
        "\n",
        "results = optimizer.optimize(iterations=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QzOoMkziPlzD",
        "outputId": "f6d72a75-767b-4f50-f82d-b6350f53a5a6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting optimization with SGQ\n",
            "Initial p: 0.400\n",
            "Switch threshold: 0.5\n",
            "ðŸ”µ Iteration 0: Loss = 6.792745, p = 0.440\n",
            "ðŸ”„ Switching to SGD at iteration 34 (improvement stalled)\n",
            "ðŸ”´ Iteration 100: Loss = 6.065800, p = 0.157\n",
            "ðŸ”´ Iteration 200: Loss = 5.978937, p = 0.157\n",
            "ðŸ”´ Iteration 300: Loss = 5.920213, p = 0.157\n",
            "ðŸ”´ Iteration 400: Loss = 5.953159, p = 0.157\n",
            "Early stopping at iteration 425 (no improvement for 100 iterations)\n",
            "Optimization completed in 426 iterations\n",
            "Final mode: SGD\n",
            "Final loss: 5.941225\n",
            "Final p: 0.157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('final results')\n",
        "print(f'loss: {optimizer.loss_history[-1]:.6f}')\n",
        "print(f'best loss: {optimizer.best_loss:.6f}')\n",
        "print(f'final mode: {optimizer.algorithm_mode}')\n",
        "print(f'final p: {optimizer.p_history[-1]:.3f}')\n",
        "print(f'total iteration: {optimizer.iteration}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZuJGiSTQj4k",
        "outputId": "c63c3680-6483-418a-a76a-4711acc03de9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final results\n",
            "loss: 5.941225\n",
            "best loss: 5.916612\n",
            "final mode: SGD\n",
            "final p: 0.157\n",
            "total iteration: 426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_loss = optimizer.loss_history[0]\n",
        "final_loss = optimizer.loss_history[-1]\n",
        "\n",
        "improvement = (initial_loss - final_loss) / initial_loss * 100\n",
        "\n",
        "print(f'improvement: {improvement:.1f}%')\n",
        "print(f'initial loss: {initial_loss:.6f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox8tdMA_QnKK",
        "outputId": "34d8ec0f-8a6d-4546-a213-964f1784168b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "improvement: 12.5%\n",
            "initial loss: 6.792745\n"
          ]
        }
      ]
    }
  ]
}